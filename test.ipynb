{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Reshape, Input\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.astype(np.float64)[:150] / 255.\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "compression_level = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_im = Input(shape=(28,28,1))\n",
    "layer0 = Reshape((28**2,))(input_im)\n",
    "layer1 = Dense(4*28**2, activation='sigmoid')(layer0)\n",
    "layer2 = Dense(compression_level, activation='relu')(layer1)\n",
    "\n",
    "encoder = Model(input_im, layer2)\n",
    "\n",
    "input_de = Input(shape=(compression_level,))\n",
    "layer3 = Dense(4*28**2, activation='sigmoid', input_shape=(compression_level,))(input_de)\n",
    "layer4 = Dense(28**2, activation='sigmoid')(layer3)\n",
    "outlayer = Reshape((28,28,1))(layer4)\n",
    "\n",
    "decoder = Model(input_de, outlayer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 14:37:30.609771: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "autoencoder = Model(inputs=input_im, outputs=decoder(encoder(input_im)))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "autoencoder.fit(X_train, X_train, 150, 200, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-27 14:37:31.025382: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 19s 19s/step - loss: 0.7412\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3952\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2963\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2855\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2887\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2838\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.2788\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2793\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2804\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2774\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2726\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2697\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2692\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2682\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2656\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2624\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2602\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2593\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2587\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2578\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2564\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2549\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2537\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2528\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2520\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2511\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2499\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2486\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2473\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2461\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2448\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2435\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2421\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2406\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2391\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2377\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2364\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2352\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2342\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2334\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2328\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2324\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2321\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2318\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2315\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2312\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2308\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2303\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2297\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2291\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2284\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2278\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2271\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2264\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2257\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2249\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2240\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2230\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2219\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2207\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2195\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2181\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2168\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2154\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2141\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2128\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2116\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2105\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2095\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2086\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2076\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2066\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2054\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2041\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2027\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2012\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1996\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1980\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1963\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1946\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1929\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1913\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1897\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1883\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1870\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1858\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1847\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1836\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1827\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1818\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1809\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1799\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1790\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1781\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1771\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1761\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1750\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1740\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1729\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1718\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1707\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1697\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1686\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1676\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1667\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1657\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1648\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1639\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1631\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1622\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1614\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1605\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1596\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1587\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1578\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1570\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1561\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1552\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1544\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1536\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1527\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1519\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1512\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1504\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1496\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1489\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.1481\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1474\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1466\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1459\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1452\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1445\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1438\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1431\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1424\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1417\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1410\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1403\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1396\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1389\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1383\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1376\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1370\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1363\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1357\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1350\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1344\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1337\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1331\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1325\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1318\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1312\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1306\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1300\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1293\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1287\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1281\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1275\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1269\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1263\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1257\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1251\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1245\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1239\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1233\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1227\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1221\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1215\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1209\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1203\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1197\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1191\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1185\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1179\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1173\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1168\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1162\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1156\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1151\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1145\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1139\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1134\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1128\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1123\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1117\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1112\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1106\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1101\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1095\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1090\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1085\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1079\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1074\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1069\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1064\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1059\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1053\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1048\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1043\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1038\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ea436a0>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a = X_test[:100]\n",
    "\n",
    "a = autoencoder.predict(a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "n=8\n",
    "\n",
    "plt.imshow(X_test[n], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(a[n], cmap='gray')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "b = encoder.predict(a[:1])\n",
    "print(a.shape)\n",
    "b > 0\n",
    "plt.imshow(decoder.predict(b>0)[0])\n",
    "plt.show()\n",
    "b"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(100, 28, 28, 1)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPsElEQVR4nO3dW4xd9XXH8d+am42HsbExDK49JGAhISdtnXTqRIVWtCiUEBKgimh4iGiF6jwEiah5KKIPoVIfUNQQobaK5BQap6TQKAkFqeQCbhI3fUAMxAWbu8EGu7bHxgbfPbfVh9mmA8xeezh3z/p+pNGc2evss5fPzM/7nPPfe//N3QVg/utqdwMAWoOwA0kQdiAJwg4kQdiBJHpaubE+W+AL1d/KTQKpnNQxjfkpm61WV9jN7GpJ90jqlvRP7n5XdP+F6tcn7Mp6Ngkg8IRvKq3V/DLezLol/aOkT0taI+kmM1tT6+MBaK563rOvk/SKu7/q7mOSHpR0XWPaAtBo9YR9paQ3Zvy8q1j2Lma23sxGzGxkXKfq2ByAejT903h33+Duw+4+3KsFzd4cgBL1hH23pKEZP68qlgHoQPWE/UlJl5jZRWbWJ+kLkh5pTFsAGq3moTd3nzCzWyX9VNNDb/e5+7aGdQagoeoaZ3f3RyU92qBeADQRh8sCSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kERLp2xGB+rqrmt1643/hLoGzi6t+fETdW3bx8ZqX3dioq5tn4nYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzz3PWE/+Ku1f9RlifPHegru2/fXH5OPvCg/FYd9/+Y2G9++jJsO5vHy6tTR48FK4r97h+Bqor7Ga2Q9IRSZOSJtx9uBFNAWi8RuzZ/9DdDzTgcQA0Ee/ZgSTqDbtL+pmZPWVm62e7g5mtN7MRMxsZ16k6NwegVvW+jL/c3Xeb2fmSHjOzF9x988w7uPsGSRskabEtm3+fegBniLr27O6+u/g+KukhSesa0RSAxqs57GbWb2YDp29LukrS1kY1BqCx6nkZPyjpITM7/Tj/6u4/aUhXeLfp5ziol/+f3b383HDVV25ZGdZ7P1I+Vi1J5w0cDetvHirv7YKNC8N11RXviyaWx8cAdO0djR8/mZrD7u6vSvrtBvYCoIkYegOSIOxAEoQdSIKwA0kQdiAJTnGdB3ouLB8+e/3zq8J1B9ftCet/OjQS1j/V/0JY/+nRNaW1uz/7x+G6K36xOKwv3h6fAuvjwSm08/AU1irs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZzwDW0xvfIRgzPmf7ZLjqomviaY8PTfSH9X/Yf0VY/+X9v1taWxgPo+vU4ngsfHxxX1jv6y7fl/l4vO35iD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsn6OoOy9Yb/5qmlpZfUvnNj8aPPX7yrLB+cioe4//xSx8J6z40VVobeC3e15yzPT4G4M01C8L6ypeWl9amdu0O152P57uzZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn7wBdffFYtp0VT208ubD813jWaDxePLo/Pql8fEU8Tn/5xdvD+lOLyq9bP3h/vK+x8fhc/P5zK87zHw9OWg+muZYkebztM1Hlnt3M7jOzUTPbOmPZMjN7zMxeLr4vbW6bAOo1l5fx35F09XuW3S5pk7tfImlT8TOADlYZdnffLOngexZfJ2ljcXujpOsb2xaARqv1Pfugu5+eJGyvpMGyO5rZeknrJWmhFtW4OQD1qvvTeHd3SaWfArn7BncfdvfhXsUnLgBonlrDvs/MVkhS8X20cS0BaIZaw/6IpJuL2zdLergx7QBolsr37Gb2gKQrJC03s12SvibpLknfN7NbJO2UdGMzmzzjVZyvrt6K8eLJeMy3Z8+h0trgwXgO867Pxr19ZsmWsL5h7xVhfeKp8lHZ7v07w3WnlpWfpy9Ji198O17/raDu5efZz1eVYXf3m0pKVza4FwBNxOGyQBKEHUiCsANJEHYgCcIOJMEprq0wFQ+d+YkTYb1raGX8+GalpeOrl4Wrfv5Dvwjrl/bGQ3fDS3aE9V9PrimtTZ53Trhu1a7ItsWn106NBae4zsNLRVdhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gGsJ/41eE98Gqr3l19q+o2r4nWvHXgmrJ/f3R/WL+iJTzNd9HsHSmvHXogvStxzPD4NdWFXxb6q4viGbNizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLN3AJ+Mx5O7TpwK6xPnl0+7PLV4Ily31+Jtj1dMXTzU+2ZYPzle/ic2NhQfA7Bi89GwbgviGYaiPdnUyfg5nY9j9OzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtk7gFdMyTx1IB7L1tDy0lLf/8bTQf/X8dVhfVH/K2H97/d8Lqz3/6D8GIDJBfG127sPVEzJfCoeK/exsaCYb8rmyj27md1nZqNmtnXGsjvNbLeZbSm+rmlumwDqNZeX8d+RdPUsy7/p7muLr0cb2xaARqsMu7tvlnSwBb0AaKJ6PqC71cyeKV7ml15MzMzWm9mImY2Mq+J4ZABNU2vYvyVptaS1kvZI+kbZHd19g7sPu/twr+ITFwA0T01hd/d97j7p7lOSvi1pXWPbAtBoNYXdzFbM+PEGSVvL7gugM1SOs5vZA5KukLTczHZJ+pqkK8xsrSSXtEPSl5rXYgIV505b/5Kw3vva3tLa6vsHwnX/duW1Yf3IJx4P69v+/dKwvmrbW6W1rr3x8QNeNYd6MC+9JPlEcC5/xbrzUWXY3f2mWRbf24ReADQRh8sCSRB2IAnCDiRB2IEkCDuQBKe4ngGmDseXVO46q3zKZg3EUy4vfL0vrP/b47OdA/X/LvzvN8K6Hyo/TdX74tNvZfG+yM6O/206fry8VjWsNw+xZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn7wRVp1tWXPY4uhT1+MpzwnXPebFiuuiKmYurxsqj00y94lLQXQNnxxufqthXJRxLj7BnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdvhapx9IrzttXdHde7ytfvORpMWyxpbCCepefwxfGmF7y1LKyfdaJ8LH1y/4Fw3am3j4R16+XP94Ngzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTBQ2QqVUw/H5arzuk9+/KLS2mt/Ev9//pnfeTqsn9cXj3X/+LfWhPVjD15YWlv20OFw3amj8fXyfTw+hgDvVrlnN7MhM/u5mT1nZtvM7LZi+TIze8zMXi6+L21+uwBqNZeX8ROSvuruayR9UtKXzWyNpNslbXL3SyRtKn4G0KEqw+7ue9z96eL2EUnPS1op6TpJG4u7bZR0fZN6BNAAH+g9u5l9WNLHJD0hadDd9xSlvZIGS9ZZL2m9JC3UopobBVCfOX8ab2ZnS/qhpK+4+7s+WXF3lzTrp1DuvsHdh919uFfxSRcAmmdOYTezXk0H/Xvu/qNi8T4zW1HUV0gabU6LABqh8mW8mZmkeyU97+53zyg9IulmSXcV3x9uSofzQVd8imo45bIkXzXrO6R3RMNr91x5f7jupX37w/q4x/uDXouvNf2D/j8qrU0dC6ZURsPN5T37ZZK+KOlZM9tSLLtD0yH/vpndImmnpBub0iGAhqgMu7v/SuWHfVzZ2HYANAuHywJJEHYgCcIOJEHYgSQIO5AEp7i2gFVcCvrQDb8Z1odv+3VY//MlL5TWvr796nDdywZfDetLuk+E9V/uvySsX7Cp/FiryYqpqJlyubHYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzt0DX4vhS0Pt+Pz4nfO/JgbD+N69fW1ob2744XPc/Dl4Q1scH4rHu1f+8N6xP7XwjrKN12LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs7fA5MFDYf3Sv3wurB/65KVhfehw+dTFXS9uC9dVb/wn4GPjYX2y6trvU/ExBGgd9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMRc5mcfkvRdSYOSXNIGd7/HzO6U9BeSTk/wfYe7P9qsRs9oFdc/nzp2LKz3/OfTFQ9f/viTVjYB7zsrx3XMG3M5qGZC0lfd/WkzG5D0lJk9VtS+6e5/17z2ADTKXOZn3yNpT3H7iJk9L2llsxsD0Fgf6D27mX1Y0sckPVEsutXMnjGz+8xsack6681sxMxGxnWqvm4B1GzOYTezsyX9UNJX3P2wpG9JWi1prab3/N+YbT133+Duw+4+3KsF9XcMoCZzCruZ9Wo66N9z9x9Jkrvvc/dJd5+S9G1J65rXJoB6VYbdzEzSvZKed/e7ZyxfMeNuN0ja2vj2ADTKXD6Nv0zSFyU9a2ZbimV3SLrJzNZqejhuh6QvNaE/SPUNjzG0hsJcPo3/laTZBmsZUwfOIBxBByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMKiyxA3fGNm+yXtnLFouaQDLWvgg+nU3jq1L4neatXI3j7k7ufNVmhp2N+3cbMRdx9uWwOBTu2tU/uS6K1WreqNl/FAEoQdSKLdYd/Q5u1HOrW3Tu1LordataS3tr5nB9A67d6zA2gRwg4k0Zawm9nVZvaimb1iZre3o4cyZrbDzJ41sy1mNtLmXu4zs1Ez2zpj2TIze8zMXi6+zzrHXpt6u9PMdhfP3RYzu6ZNvQ2Z2c/N7Dkz22ZmtxXL2/rcBX215Hlr+Xt2M+uW9JKkT0naJelJSTe5+3MtbaSEme2QNOzubT8Aw8z+QNJRSd91948Wy74u6aC731X8R7nU3f+qQ3q7U9LRdk/jXcxWtGLmNOOSrpf0Z2rjcxf0daNa8Ly1Y8++TtIr7v6qu49JelDSdW3oo+O5+2ZJB9+z+DpJG4vbGzX9x9JyJb11BHff4+5PF7ePSDo9zXhbn7ugr5ZoR9hXSnpjxs+71Fnzvbukn5nZU2a2vt3NzGLQ3fcUt/dKGmxnM7OonMa7ld4zzXjHPHe1TH9eLz6ge7/L3f3jkj4t6cvFy9WO5NPvwTpp7HRO03i3yizTjL+jnc9drdOf16sdYd8taWjGz6uKZR3B3XcX30clPaTOm4p63+kZdIvvo23u5x2dNI33bNOMqwOeu3ZOf96OsD8p6RIzu8jM+iR9QdIjbejjfcysv/jgRGbWL+kqdd5U1I9Iurm4fbOkh9vYy7t0yjTeZdOMq83PXdunP3f3ln9JukbTn8hvl/TX7eihpK+LJf1P8bWt3b1JekDTL+vGNf3Zxi2SzpW0SdLLkh6XtKyDevsXSc9KekbTwVrRpt4u1/RL9GckbSm+rmn3cxf01ZLnjcNlgST4gA5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvg/Ct6sqYl0e9MAAAAASUVORK5CYII="
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      , 69.50743 ,  0.      , 19.24131 ,  0.      ,\n",
       "         0.      , 11.612603,  0.      ,  0.      ,  0.      , 60.54023 ,\n",
       "        53.382904,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "         0.      , 21.43809 ,  0.      ,  0.      ,  0.      ,  8.893706,\n",
       "         0.      , 10.596368,  0.      , 42.83391 , 35.94171 , 72.08287 ,\n",
       "        72.79234 ,  0.      ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "def compress(frame):\n",
    "    import numpy as np\n",
    "    # import matplotlib.pyplot as plt\n",
    "    frame = frame.astype(np.float64)/255.\n",
    "    block_size = 28\n",
    "    size = frame.shape[0] // block_size, frame.shape[1] // block_size\n",
    "    im_size = np.array([*size, 0])*block_size\n",
    "    im_size[2] = 1\n",
    "    res_img = np.zeros(im_size)\n",
    "    blocks = np.zeros((size[0]*size[1], 28, 28, 1))\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            blocks[i*size[1]+j] = frame[block_size*i:block_size*(i+1), block_size*j:block_size*(j+1), :1]   \n",
    "    result = autoencoder.predict(blocks.reshape((size[0]*size[1], block_size, block_size, 1)))\n",
    "    \n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            res_img[block_size*i:block_size*(i+1), block_size*j:block_size*(j+1)] = result[i*size[1]+j]\n",
    "    # cv2.imshow('abc', res_img)\n",
    "    return res_img     \n",
    "    # red = np.array([[frame[i, j, 0] for j in range(frame.shape[1])] for i in range(frame.shape[0])])\n",
    "    # channels = [np.array([[frame[i, j, k] for j in range(frame.shape[1])] for i in range(frame.shape[0])]) for k in range(frame.shape[2])]\n",
    "    # cv2.imshow('123', channels[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    res = compress(frame)\n",
    "    # break\n",
    "    cv2.imshow('scr', res)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n",
      "work\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yv/4z0g81051cs2v9b48d0pn0pw0000gn/T/ipykernel_70708/3131441140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yv/4z0g81051cs2v9b48d0pn0pw0000gn/T/ipykernel_70708/688745074.py\u001b[0m in \u001b[0;36mcompress\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}